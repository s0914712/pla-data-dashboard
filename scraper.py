from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
from datetime import datetime
import os

# ==================== è¨­å®šå€ ====================
CSV_FILE = 'data/JapanandBattleship.csv'
base_url = "https://www.mnd.gov.tw/news/plaactlist"
total_pages = 4
start_page = 1
# =================================================

def init_driver():
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver

def extract_numbers_from_text(text):
    """å¾æ–‡æœ¬ä¸­æå–å…±æ©Ÿå…±è‰¦æ•¸é‡"""
    aircraft_patterns = [
        r'å…±æ©Ÿ\s*(\d+)\s*æ¶æ¬¡',
        r'å…±æ©Ÿï¼š?\s*(\d+)',
        r'(\d+)\s*æ¶æ¬¡',
    ]

    vessel_patterns = [
        r'å…±è‰¦\s*(\d+)\s*è‰˜',
        r'å…±è‰¦ï¼š?\s*(\d+)',
        r'(\d+)\s*è‰˜',
    ]

    aircraft = 0
    vessel = 0

    for pattern in aircraft_patterns:
        match = re.search(pattern, text)
        if match:
            try:
                aircraft = int(match.group(1))
                break
            except:
                continue

    for pattern in vessel_patterns:
        match = re.search(pattern, text)
        if match:
            try:
                vessel = int(match.group(1))
                break
            except:
                continue

    return aircraft, vessel

def get_latest_date_from_csv():
    """å¾ CSV è®€å–æœ€æ–°æ—¥æœŸ"""
    try:
        if not os.path.exists(CSV_FILE):
            print(f"âš ï¸ CSV æª”æ¡ˆä¸å­˜åœ¨: {CSV_FILE}")
            return None
            
        df = pd.read_csv(CSV_FILE, encoding='utf-8-sig')
        
        if df.empty or 'date' not in df.columns:
            return None
        
        # è½‰æ›æ—¥æœŸä¸¦æ‰¾å‡ºæœ€æ–°çš„
        dates = pd.to_datetime(df['date'], format='%Y/%m/%d', errors='coerce')
        latest_date = dates.max()
        
        if pd.isna(latest_date):
            return None
            
        return latest_date
        
    except Exception as e:
        print(f"è®€å– CSV æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def save_to_csv(new_data):
    """å°‡æ–°è³‡æ–™é™„åŠ åˆ° CSV"""
    if not new_data:
        print("â„¹ï¸ æ²’æœ‰æ–°è³‡æ–™éœ€è¦å¯«å…¥")
        return
    
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    os.makedirs(os.path.dirname(CSV_FILE), exist_ok=True)
    
    # è®€å–ç¾æœ‰è³‡æ–™
    if os.path.exists(CSV_FILE):
        df_existing = pd.read_csv(CSV_FILE, encoding='utf-8-sig')
    else:
        # å¦‚æœæª”æ¡ˆä¸å­˜åœ¨ï¼Œå‰µå»ºæ–°çš„ DataFrame
        df_existing = pd.DataFrame(columns=['date', 'pla_aircraft_sorties', 'plan_vessel_sorties'])
    
    # å‰µå»ºæ–°è³‡æ–™çš„ DataFrame
    df_new = pd.DataFrame(new_data, columns=['date', 'pla_aircraft_sorties', 'plan_vessel_sorties'])
    
    # åˆä½µè³‡æ–™
    df_combined = pd.concat([df_existing, df_new], ignore_index=True)
    
    # æŒ‰æ—¥æœŸæ’åº
    df_combined['date'] = pd.to_datetime(df_combined['date'], format='%Y/%m/%d')
    df_combined = df_combined.sort_values('date')
    df_combined['date'] = df_combined['date'].dt.strftime('%Y/%m/%d')
    
    # ç§»é™¤é‡è¤‡çš„æ—¥æœŸï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰
    df_combined = df_combined.drop_duplicates(subset=['date'], keep='last')
    
    # å„²å­˜
    df_combined.to_csv(CSV_FILE, index=False, encoding='utf-8-sig')
    print(f"âœ… æˆåŠŸå¯«å…¥ {len(new_data)} ç­†è³‡æ–™åˆ° {CSV_FILE}")

def main():
    print(f"\n{'='*60}")
    print("ğŸš€ é–‹å§‹çˆ¬å–åœ‹é˜²éƒ¨è³‡æ–™...")
    print(f"{'='*60}\n")
    
    # å–å¾—æœ€æ–°æ—¥æœŸ
    latest_date = get_latest_date_from_csv()
    if latest_date:
        print(f"ğŸ“… CSV æœ€æ–°æ—¥æœŸ: {latest_date.strftime('%Y/%m/%d')}")
    else:
        print(f"ğŸ“… ç„¡ç¾æœ‰è³‡æ–™ï¼Œå°‡çˆ¬å–æ‰€æœ‰è³‡æ–™")
        latest_date = datetime.min
    
    all_data = []
    processed_urls = set()
    
    driver = init_driver()
    print("âœ“ ç€è¦½å™¨å•Ÿå‹•æˆåŠŸ\n")
    
    for page in range(start_page, total_pages + 1):
        try:
            if page == 1:
                page_url = base_url
            else:
                page_url = f"{base_url}/{page}"
            
            print(f"ğŸ“„ ç¬¬ {page} é : {page_url}")
            driver.get(page_url)
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            time.sleep(3)
            
            soup = BeautifulSoup(driver.page_source, "html.parser")
            all_links = soup.find_all('a', href=re.compile(r'news/plaact/\d+'))
            
            print(f"  æ‰¾åˆ° {len(all_links)} å€‹ plaact é€£çµ")
            
            for idx, link in enumerate(all_links, 1):
                try:
                    href = link.get('href')
                    
                    if href.startswith('/'):
                        detail_url = f"https://www.mnd.gov.tw{href}"
                    elif href.startswith('http'):
                        detail_url = href
                    else:
                        detail_url = f"https://www.mnd.gov.tw/{href}"
                    
                    if detail_url in processed_urls:
                        continue
                    processed_urls.add(detail_url)
                    
                    # æå–æ—¥æœŸ
                    date_elem = link.find('h5', class_='date')
                    if date_elem:
                        date_span = date_elem.find('span', class_='en')
                        date_text = date_span.get_text(strip=True) if date_span else date_elem.get_text(strip=True)
                    else:
                        date_text = None
                    
                    if date_text:
                        date_match = re.search(r'(\d{3,4})[./](\d{1,2})[./](\d{1,2})', date_text)
                        if date_match:
                            year = int(date_match.group(1))
                            if year < 1000:
                                year += 1911
                            month = date_match.group(2).zfill(2)
                            day = date_match.group(3).zfill(2)
                            date = f"{year}/{month}/{day}"
                        else:
                            date = None
                    else:
                        date = None
                    
                    if not date:
                        print(f"  [{idx:2d}] âš ï¸ æ‰¾ä¸åˆ°æ—¥æœŸï¼Œè·³é")
                        continue
                    
                    try:
                        current_date = datetime.strptime(date, '%Y/%m/%d')
                    except:
                        print(f"  [{idx:2d}] âš ï¸ æ—¥æœŸæ ¼å¼éŒ¯èª¤: {date}")
                        continue
                    
                    if current_date <= latest_date:
                        print(f"  [{idx:2d}] {date} â­ï¸  å·²å­˜åœ¨")
                        continue
                    
                    # æª¢æŸ¥æ¨™é¡Œ
                    title_elem = link.find('h4', class_='title')
                    if title_elem:
                        title_text = title_elem.get_text(strip=True)
                        if 'ä¸­å…±è§£æ”¾è»' not in title_text and 'è‡ºæµ·' not in title_text and 'ç©ºåŸŸå‹•æ…‹' not in title_text:
                            print(f"  [{idx:2d}] {date} â­ï¸  éç›¸é—œæ¨™é¡Œ")
                            continue
                    
                    # è¨ªå•è©³ç´°é é¢
                    print(f"  [{idx:2d}] {date} â³ è®€å–ä¸­...", end=" ")
                    driver.get(detail_url)
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.TAG_NAME, "body"))
                    )
                    time.sleep(2)
                    
                    detail_soup = BeautifulSoup(driver.page_source, "html.parser")
                    
                    content_areas = [
                        detail_soup.find('div', class_='content'),
                        detail_soup.find('div', class_='article'),
                        detail_soup.find('article'),
                        detail_soup.find('main'),
                        detail_soup.body
                    ]
                    
                    body_text = ""
                    for area in content_areas:
                        if area:
                            body_text = area.get_text(separator="\n", strip=True)
                            break
                    
                    # æå–æ•¸é‡
                    aircraft, vessel = extract_numbers_from_text(body_text)
                    
                    # å„²å­˜è³‡æ–™ [date, aircraft, vessel]
                    all_data.append([date, aircraft, vessel])
                    print(f"âœ“ å…±æ©Ÿ {aircraft:2d} | å…±è‰¦ {vessel:2d}")
                    
                    driver.back()
                    time.sleep(2)
                    
                except Exception as e:
                    print(f"\n  âŒ è™•ç†é …ç›® {idx} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    driver.get(page_url)
                    time.sleep(3)
                    continue
        
        except Exception as e:
            print(f"âŒ è™•ç†ç¬¬ {page} é å¤±æ•—: {e}")
            continue
    
    driver.quit()
    print("\nâœ“ ç€è¦½å™¨å·²é—œé–‰")
    
    # å„²å­˜è³‡æ–™
    print(f"\n{'='*60}")
    if all_data:
        # æŒ‰æ—¥æœŸæ’åº
        all_data.sort(key=lambda x: datetime.strptime(x[0], '%Y/%m/%d'))
        
        save_to_csv(all_data)
        
        print(f"\nâœ… å®Œæˆï¼")
        print(f"ğŸ“Š ç¸½å…±çˆ¬å– {len(all_data)} ç­†æ–°è³‡æ–™")
        
        # é¡¯ç¤ºè³‡æ–™æ‘˜è¦
        print(f"\næœ€æ–° 5 ç­†è³‡æ–™:")
        print(f"{'æ—¥æœŸ':<12} | {'å…±æ©Ÿ':<4} | {'å…±è‰¦':<4}")
        print("â”€" * 30)
        for row in all_data[-5:]:
            print(f"{row[0]:<12} | {row[1]:>4} | {row[2]:>4}")
    else:
        print("â„¹ï¸ æ²’æœ‰æ–°è³‡æ–™éœ€è¦å¯«å…¥")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()
