#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PLA 7-Day Sorties Prediction System
====================================
æ•´åˆæ¨¡å‹ï¼šæ”¿æ²»äº‹ä»¶é«˜æ¶æ¬¡é è­¦ + æ­£å¸¸æ—¥å›æ­¸é æ¸¬

åŠŸèƒ½ï¼š
1. è¼‰å…¥æœ€æ–°è³‡æ–™
2. è¨“ç·´æ•´åˆæ¨¡å‹
3. ç”Ÿæˆæœªä¾†7å¤©é æ¸¬
4. è¼¸å‡º prediction.csv

Author: PLA Data Dashboard
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
import warnings
import os

warnings.filterwarnings('ignore')

# ============================================================
# é…ç½®
# ============================================================

# è³‡æ–™ä¾†æº (å¯è¨­ç‚ºæœ¬åœ°è·¯å¾‘æˆ– GitHub raw URL)
DATA_SOURCES = {
    'sorties': 'https://raw.githubusercontent.com/s0914712/pla-data-dashboard/main/data/JapanandBattleship.csv',
    'political': 'https://raw.githubusercontent.com/s0914712/pla-data-dashboard/main/data/merged_comprehensive_data_M.csv'
}

# æ¨¡å‹åƒæ•¸
HIGH_THRESHOLD = 60  # é«˜æ¶æ¬¡é–€æª»
PREDICTION_DAYS = 7  # é æ¸¬å¤©æ•¸


class PLAPredictor:
    """
    PLA æ¶æ¬¡é æ¸¬ç³»çµ±
    
    æ•´åˆï¼š
    1. åˆ†é¡æ¨¡å‹ï¼šé æ¸¬é«˜æ¶æ¬¡æ©Ÿç‡ (>=60)
    2. æ­£å¸¸æ—¥å›æ­¸ï¼šé æ¸¬æ­£å¸¸ç‹€æ…‹åŸºç·š
    3. é«˜æ¶æ¬¡å›æ­¸ï¼šé æ¸¬é«˜å¼·åº¦ç‹€æ…‹
    """
    
    def __init__(self, high_threshold=60):
        self.high_threshold = high_threshold
        self.clf_model = None
        self.reg_normal = None
        self.reg_high = None
        self.scaler = StandardScaler()
        self.feature_cols = []
        self.political_events = None
        self.latest_data = None
        self.latest_date = None
        
    def load_data(self, sorties_path=None, political_path=None):
        """è¼‰å…¥è³‡æ–™"""
        print("=" * 60)
        print("PLA 7-Day Prediction System")
        print("=" * 60)
        print(f"\n[1] è¼‰å…¥è³‡æ–™...")
        
        sorties_path = sorties_path or DATA_SOURCES['sorties']
        political_path = political_path or DATA_SOURCES['political']
        
        # è¼‰å…¥æ¶æ¬¡è³‡æ–™
        try:
            df_sorties = pd.read_csv(sorties_path, encoding='utf-8-sig')
        except:
            df_sorties = pd.read_csv(sorties_path, encoding='utf-8')
        
        df_sorties['date'] = pd.to_datetime(df_sorties['date'])
        df_sorties = df_sorties[df_sorties['pla_aircraft_sorties'].notna()].copy()
        df_sorties = df_sorties.sort_values('date').reset_index(drop=True)
        
        # è¼‰å…¥æ”¿æ²»äº‹ä»¶è³‡æ–™
        try:
            df_political = pd.read_csv(political_path, encoding='utf-8-sig')
        except:
            df_political = pd.read_csv(political_path, encoding='utf-8')
        
        df_political['date'] = pd.to_datetime(df_political['date'], errors='coerce')
        df_political = df_political[df_political['date'].notna()].copy()
        
        self.political_events = df_political
        self.latest_date = df_sorties['date'].max()
        
        print(f"  æ¶æ¬¡è³‡æ–™: {len(df_sorties)} ç­†")
        print(f"  æ”¿æ²»äº‹ä»¶: {len(df_political)} ç­†")
        print(f"  æœ€æ–°æ—¥æœŸ: {self.latest_date.strftime('%Y-%m-%d')}")
        
        return df_sorties, df_political
    
    def _create_political_features(self, df, df_events, window_days):
        """å»ºç«‹æ”¿æ²»äº‹ä»¶ç‰¹å¾µ"""
        features = []
        
        for _, row in df.iterrows():
            current_date = row['date']
            
            mask = (df_events['date'] >= current_date - timedelta(days=window_days)) & \
                   (df_events['date'] < current_date)
            past_events = df_events[mask]
            
            # ç¾å°äº’å‹•
            us_tw = 0
            if 'US_Taiwan_interaction' in past_events.columns:
                us_tw = (past_events['US_Taiwan_interaction'].notna() & 
                         (past_events['US_Taiwan_interaction'].astype(str).str.len() > 2)).sum()
            
            # ä¸­å…±æ”¿æ²»è²æ˜
            cn_stmt = 0
            if 'Political_statement' in past_events.columns:
                cn_stmt = past_events['Political_statement'].astype(str).str.contains(
                    'ä¸­å…±|ä¸­åœ‹|ä¸­æ–¹|åœ‹å°è¾¦', na=False).sum()
            
            # å¤–è‰¦é€šé
            foreign_ship = 0
            if 'Foreign_battleship' in past_events.columns:
                foreign_ship = (past_events['Foreign_battleship'].notna() & 
                                (past_events['Foreign_battleship'].astype(str).str.len() > 2)).sum()
            
            feat = {
                f'us_tw_{window_days}d': us_tw,
                f'cn_stmt_{window_days}d': cn_stmt,
                f'foreign_ship_{window_days}d': foreign_ship,
            }
            features.append(feat)
        
        return pd.DataFrame(features)
    
    def prepare_features(self, df_sorties, df_political):
        """æº–å‚™è¨“ç·´ç‰¹å¾µ"""
        print(f"\n[2] ç‰¹å¾µå·¥ç¨‹...")
        
        df = df_sorties.copy()
        target = 'pla_aircraft_sorties'
        
        # æ™‚é–“ç‰¹å¾µ
        df['month'] = df['date'].dt.month
        df['day_of_week'] = df['date'].dt.dayofweek
        df['high_risk_month'] = df['date'].dt.month.isin([4, 8, 9, 10]).astype(int)
        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        
        # Lag ç‰¹å¾µ
        for lag in [1, 2, 3, 7, 14, 30]:
            df[f'lag_{lag}'] = df[target].shift(lag)
        
        # ç§»å‹•çµ±è¨ˆ
        for window in [3, 7, 14, 30]:
            df[f'ma_{window}'] = df[target].shift(1).rolling(window, min_periods=1).mean()
            df[f'min_{window}'] = df[target].shift(1).rolling(window, min_periods=1).min()
            df[f'max_{window}'] = df[target].shift(1).rolling(window, min_periods=1).max()
            df[f'std_{window}'] = df[target].shift(1).rolling(window, min_periods=1).std()
        
        df['has_zero_7d'] = (df['min_7'] == 0).astype(int)
        df['compression'] = df['ma_3'] / (df['ma_14'] + 1)
        
        # æµ·è»æ´»å‹•
        if 'è‰¦é€šé' in df.columns:
            df['naval_pass'] = df['è‰¦é€šé'].fillna(0)
        else:
            df['naval_pass'] = 0
            
        if 'èˆªæ¯æ´»å‹•' in df.columns:
            df['carrier'] = df['èˆªæ¯æ´»å‹•'].fillna(0)
        else:
            df['carrier'] = 0
        
        # æ”¿æ²»äº‹ä»¶ç‰¹å¾µ
        for window in [3, 7]:
            pol_feat = self._create_political_features(df, df_political, window)
            for col in pol_feat.columns:
                df[col] = pol_feat[col].values
        
        # ç›®æ¨™è®Šæ•¸
        df['is_high'] = (df[target] >= self.high_threshold).astype(int)
        
        # ç§»é™¤ NaN
        df = df.dropna(subset=['lag_30', 'ma_30']).copy()
        
        # å®šç¾©ç‰¹å¾µ
        self.feature_cols = [
            'month', 'day_of_week', 'high_risk_month', 'is_weekend',
            'lag_1', 'lag_2', 'lag_3', 'lag_7', 'lag_14', 'lag_30',
            'ma_3', 'ma_7', 'ma_14', 'ma_30',
            'min_3', 'min_7', 'min_14', 'min_30',
            'max_3', 'max_7', 'max_14', 'max_30',
            'std_3', 'std_7', 'std_14', 'std_30',
            'has_zero_7d', 'compression',
            'naval_pass', 'carrier',
            'us_tw_3d', 'cn_stmt_3d', 'foreign_ship_3d',
            'us_tw_7d', 'cn_stmt_7d', 'foreign_ship_7d'
        ]
        
        self.latest_data = df
        
        print(f"  ç‰¹å¾µæ•¸: {len(self.feature_cols)}")
        print(f"  è¨“ç·´æ¨£æœ¬: {len(df)}")
        print(f"  é«˜æ¶æ¬¡æ¨£æœ¬: {df['is_high'].sum()} ({df['is_high'].mean()*100:.2f}%)")
        
        return df
    
    def train(self, df):
        """è¨“ç·´æ¨¡å‹"""
        print(f"\n[3] è¨“ç·´æ¨¡å‹...")
        
        target = 'pla_aircraft_sorties'
        X = df[self.feature_cols].values
        y_reg = df[target].values
        y_clf = df['is_high'].values
        
        # æ¨™æº–åŒ–
        X_scaled = self.scaler.fit_transform(X)
        
        # ========== 1. åˆ†é¡æ¨¡å‹ ==========
        print("  è¨“ç·´åˆ†é¡æ¨¡å‹ (é«˜æ¶æ¬¡é è­¦)...")
        k = min(5, int(y_clf.sum()) - 1)
        if k >= 1:
            smote = SMOTE(random_state=42, k_neighbors=k)
            X_res, y_res = smote.fit_resample(X_scaled, y_clf)
        else:
            X_res, y_res = X_scaled, y_clf
        
        self.clf_model = RandomForestClassifier(
            n_estimators=200, max_depth=6, 
            class_weight='balanced', random_state=42
        )
        self.clf_model.fit(X_res, y_res)
        
        # ========== 2. æ­£å¸¸æ—¥å›æ­¸æ¨¡å‹ ==========
        print("  è¨“ç·´æ­£å¸¸æ—¥å›æ­¸æ¨¡å‹...")
        normal_mask = y_reg < self.high_threshold
        X_normal = X[normal_mask]
        y_normal = y_reg[normal_mask]
        
        from sklearn.ensemble import GradientBoostingRegressor
        self.reg_normal = GradientBoostingRegressor(
            n_estimators=200, max_depth=4, learning_rate=0.05,
            random_state=42
        )
        self.reg_normal.fit(X_normal, y_normal)
        
        # ========== 3. é«˜æ¶æ¬¡å›æ­¸æ¨¡å‹ ==========
        print("  è¨“ç·´é«˜æ¶æ¬¡å›æ­¸æ¨¡å‹...")
        high_mask = y_reg >= 30  # ç”¨è¼ƒä½é–€æª»å¢åŠ æ¨£æœ¬
        X_high = X[high_mask]
        y_high = y_reg[high_mask]
        
        self.reg_high = GradientBoostingRegressor(
            n_estimators=150, max_depth=4, learning_rate=0.05,
            random_state=42
        )
        self.reg_high.fit(X_high, y_high)
        
        print("  æ¨¡å‹è¨“ç·´å®Œæˆï¼")
        
        return self
    
    def _get_future_political_features(self, target_date, window_days):
        """å–å¾—æœªä¾†æ—¥æœŸçš„æ”¿æ²»äº‹ä»¶ç‰¹å¾µ"""
        if self.political_events is None:
            return {f'us_tw_{window_days}d': 0, f'cn_stmt_{window_days}d': 0, f'foreign_ship_{window_days}d': 0}
        
        mask = (self.political_events['date'] >= target_date - timedelta(days=window_days)) & \
               (self.political_events['date'] < target_date)
        past = self.political_events[mask]
        
        us_tw = 0
        if 'US_Taiwan_interaction' in past.columns:
            us_tw = (past['US_Taiwan_interaction'].notna() & 
                     (past['US_Taiwan_interaction'].astype(str).str.len() > 2)).sum()
        
        cn_stmt = 0
        if 'Political_statement' in past.columns:
            cn_stmt = past['Political_statement'].astype(str).str.contains(
                'ä¸­å…±|ä¸­åœ‹|ä¸­æ–¹|åœ‹å°è¾¦', na=False).sum()
        
        foreign_ship = 0
        if 'Foreign_battleship' in past.columns:
            foreign_ship = (past['Foreign_battleship'].notna() & 
                            (past['Foreign_battleship'].astype(str).str.len() > 2)).sum()
        
        return {
            f'us_tw_{window_days}d': us_tw,
            f'cn_stmt_{window_days}d': cn_stmt,
            f'foreign_ship_{window_days}d': foreign_ship
        }
    
    def predict_7_days(self):
        """é æ¸¬æœªä¾†7å¤©"""
        print(f"\n[4] ç”Ÿæˆ 7 å¤©é æ¸¬...")
        
        df = self.latest_data
        target = 'pla_aircraft_sorties'
        
        # æº–å‚™æ»¾å‹•çª—å£
        recent = df.tail(60)
        current_window = recent[target].tolist()
        
        # è¨ˆç®—æ­·å²åŸºç·š
        normal_baseline = np.mean([x for x in current_window if x < self.high_threshold])
        
        # é æ¸¬çµæœ
        predictions = []
        
        for i in range(PREDICTION_DAYS):
            target_date = self.latest_date + timedelta(days=i+1)
            
            # å»ºç«‹ç‰¹å¾µ
            pol_3d = self._get_future_political_features(target_date, 3)
            pol_7d = self._get_future_political_features(target_date, 7)
            
            features = {
                'month': target_date.month,
                'day_of_week': target_date.dayofweek,
                'high_risk_month': 1 if target_date.month in [4, 8, 9, 10] else 0,
                'is_weekend': 1 if target_date.dayofweek >= 5 else 0,
                'lag_1': current_window[-1],
                'lag_2': current_window[-2],
                'lag_3': current_window[-3],
                'lag_7': current_window[-7],
                'lag_14': current_window[-14],
                'lag_30': current_window[-30],
                'ma_3': np.mean(current_window[-3:]),
                'ma_7': np.mean(current_window[-7:]),
                'ma_14': np.mean(current_window[-14:]),
                'ma_30': np.mean(current_window[-30:]),
                'min_3': np.min(current_window[-3:]),
                'min_7': np.min(current_window[-7:]),
                'min_14': np.min(current_window[-14:]),
                'min_30': np.min(current_window[-30:]),
                'max_3': np.max(current_window[-3:]),
                'max_7': np.max(current_window[-7:]),
                'max_14': np.max(current_window[-14:]),
                'max_30': np.max(current_window[-30:]),
                'std_3': np.std(current_window[-3:]),
                'std_7': np.std(current_window[-7:]),
                'std_14': np.std(current_window[-14:]),
                'std_30': np.std(current_window[-30:]),
                'has_zero_7d': 1 if np.min(current_window[-7:]) == 0 else 0,
                'compression': np.mean(current_window[-3:]) / (np.mean(current_window[-14:]) + 1),
                'naval_pass': 0,
                'carrier': 0,
                **pol_3d,
                **pol_7d
            }
            
            X_step = pd.DataFrame([features])[self.feature_cols].values
            X_step_scaled = self.scaler.transform(X_step)
            
            # åˆ†é¡é æ¸¬
            prob_high = self.clf_model.predict_proba(X_step_scaled)[0, 1]
            
            # å›æ­¸é æ¸¬
            pred_normal = max(0, self.reg_normal.predict(X_step)[0])
            pred_high = max(0, self.reg_high.predict(X_step)[0])
            
            # æ•´åˆé æ¸¬
            if prob_high > 0.5:
                pred_ensemble = pred_high
            elif prob_high > 0.3:
                pred_ensemble = 0.5 * pred_normal + 0.5 * pred_high
            else:
                pred_ensemble = pred_normal
            
            # ä¿¡å¿ƒå€é–“
            uncertainty = 8 * (1 + i * 0.15)
            lower = max(0, pred_ensemble - 1.96 * uncertainty)
            upper = pred_ensemble + 1.96 * uncertainty
            
            # é¢¨éšªç­‰ç´š
            if prob_high > 0.5:
                risk_level = 'HIGH'
            elif prob_high > 0.3:
                risk_level = 'MEDIUM-HIGH'
            elif prob_high > 0.15:
                risk_level = 'MEDIUM'
            else:
                risk_level = 'LOW'
            
            predictions.append({
                'date': target_date.strftime('%Y-%m-%d'),
                'day_of_week': target_date.strftime('%A'),
                'predicted_sorties': round(pred_ensemble, 1),
                'lower_bound': round(lower, 1),
                'upper_bound': round(upper, 1),
                'high_event_probability': round(prob_high * 100, 1),
                'risk_level': risk_level,
                'normal_model_pred': round(pred_normal, 1),
                'high_model_pred': round(pred_high, 1),
                'political_signal_3d': pol_3d['cn_stmt_3d'] + pol_3d['us_tw_3d'],
                'political_signal_7d': pol_7d['cn_stmt_7d'] + pol_7d['us_tw_7d']
            })
            
            # æ›´æ–°çª—å£
            current_window.append(pred_ensemble)
        
        return pd.DataFrame(predictions)
    
    def run(self, sorties_path=None, political_path=None, output_path='prediction.csv'):
        """åŸ·è¡Œå®Œæ•´é æ¸¬æµç¨‹"""

        # è¼‰å…¥è³‡æ–™
        df_sorties, df_political = self.load_data(sorties_path, political_path)

        # æº–å‚™ç‰¹å¾µ
        df = self.prepare_features(df_sorties, df_political)

        # è¨“ç·´æ¨¡å‹
        self.train(df)

        # é æ¸¬
        predictions = self.predict_7_days()

        # è¼¸å‡º
        print(f"\n[5] è¼¸å‡ºé æ¸¬çµæœ...")

        # åŠ å…¥ metadata
        predictions['generated_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        predictions['model_version'] = '2.0-ensemble'
        predictions['data_latest_date'] = self.latest_date.strftime('%Y-%m-%d')

        # åˆå§‹åŒ–æ–°æ¬„ä½
        predictions['actual_sorties'] = np.nan
        predictions['prediction_error'] = np.nan

        # ========== æ­·å²è¨˜éŒ„ç®¡ç† (Append + Merge) ==========
        print(f"\n[6] æ¯”è¼ƒå¯¦éš›å€¼ä¸¦æ›´æ–°æ­·å²è¨˜éŒ„...")

        # è¼‰å…¥å¯¦éš›å€¼è³‡æ–™
        actual_data = df_sorties[['date', 'pla_aircraft_sorties']].copy()
        actual_data['date'] = actual_data['date'].dt.strftime('%Y-%m-%d')
        actual_dict = dict(zip(actual_data['date'], actual_data['pla_aircraft_sorties']))

        # è®€å–ç¾æœ‰æ­·å²è¨˜éŒ„
        existing_history = pd.DataFrame()
        if os.path.exists(output_path):
            try:
                existing_history = pd.read_csv(output_path, encoding='utf-8-sig')
                print(f"  è®€å–ç¾æœ‰è¨˜éŒ„: {len(existing_history)} ç­†")
            except:
                existing_history = pd.DataFrame()

        # æ›´æ–°ç¾æœ‰è¨˜éŒ„çš„å¯¦éš›å€¼
        if not existing_history.empty:
            for idx, row in existing_history.iterrows():
                pred_date = row['date']
                if pred_date in actual_dict:
                    actual_val = actual_dict[pred_date]
                    existing_history.loc[idx, 'actual_sorties'] = actual_val
                    if pd.notna(row['predicted_sorties']) and pd.notna(actual_val):
                        existing_history.loc[idx, 'prediction_error'] = actual_val - row['predicted_sorties']

        # åˆä½µæ–°é æ¸¬èˆ‡æ­·å²è¨˜éŒ„
        if not existing_history.empty:
            # ç§»é™¤èˆ‡æ–°é æ¸¬é‡è¤‡çš„æ—¥æœŸ
            existing_dates = set(existing_history['date'])
            new_dates = set(predictions['date'])
            overlap_dates = existing_dates & new_dates

            if overlap_dates:
                print(f"  è¦†è“‹æ—¥æœŸ: {', '.join(sorted(overlap_dates))}")
                existing_history = existing_history[~existing_history['date'].isin(overlap_dates)]

            # åˆä½µ
            combined = pd.concat([existing_history, predictions], ignore_index=True)
        else:
            combined = predictions.copy()

        # å†æ¬¡æ›´æ–°æ‰€æœ‰è¨˜éŒ„çš„å¯¦éš›å€¼
        for idx, row in combined.iterrows():
            pred_date = row['date']
            if pred_date in actual_dict:
                actual_val = actual_dict[pred_date]
                combined.loc[idx, 'actual_sorties'] = actual_val
                if pd.notna(row['predicted_sorties']) and pd.notna(actual_val):
                    combined.loc[idx, 'prediction_error'] = actual_val - row['predicted_sorties']

        # æ’åºä¸¦å„²å­˜
        combined = combined.sort_values('date').reset_index(drop=True)
        combined.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"  å·²å„²å­˜: {output_path} ({len(combined)} ç­†è¨˜éŒ„)")

        # ========== è¨ˆç®—é æ¸¬æº–ç¢ºåº¦çµ±è¨ˆ ==========
        print(f"\n[7] é æ¸¬æº–ç¢ºåº¦åˆ†æ...")

        has_actual = combined[combined['actual_sorties'].notna()]
        if len(has_actual) > 0:
            errors = has_actual['prediction_error'].dropna()
            if len(errors) > 0:
                mae = np.abs(errors).mean()
                rmse = np.sqrt((errors ** 2).mean())
                mape = (np.abs(errors) / (has_actual['actual_sorties'].dropna() + 1)).mean() * 100

                # æ–¹å‘æº–ç¢ºç‡ (é æ¸¬é«˜ä½æ–¹å‘æ˜¯å¦æ­£ç¢º)
                correct_direction = 0
                total_comparisons = 0
                for idx, row in has_actual.iterrows():
                    if pd.notna(row['predicted_sorties']) and pd.notna(row['actual_sorties']):
                        # ä»¥ 30 æ¶æ¬¡ä½œç‚ºé«˜ä½åˆ†ç•Œ
                        pred_high = row['predicted_sorties'] >= 30
                        actual_high = row['actual_sorties'] >= 30
                        if pred_high == actual_high:
                            correct_direction += 1
                        total_comparisons += 1

                direction_accuracy = (correct_direction / total_comparisons * 100) if total_comparisons > 0 else 0

                print(f"  æ­·å²é æ¸¬æ•¸: {len(has_actual)}")
                print(f"  MAE (å¹³å‡çµ•å°èª¤å·®): {mae:.2f} æ¶æ¬¡")
                print(f"  RMSE (å‡æ–¹æ ¹èª¤å·®): {rmse:.2f} æ¶æ¬¡")
                print(f"  MAPE (å¹³å‡ç™¾åˆ†æ¯”èª¤å·®): {mape:.1f}%")
                print(f"  æ–¹å‘æº–ç¢ºç‡: {direction_accuracy:.1f}%")
        else:
            print("  å°šç„¡å¯æ¯”è¼ƒçš„æ­·å²é æ¸¬")

        # é¡¯ç¤ºé æ¸¬
        print("\n" + "=" * 80)
        print("ã€7 å¤©é æ¸¬çµæœã€‘")
        print("=" * 80)
        print(f"\n{'æ—¥æœŸ':<12} {'æ˜ŸæœŸ':<10} {'é æ¸¬':>8} {'95% CI':>15} {'é«˜æ¶æ¬¡æ©Ÿç‡':>10} {'é¢¨éšª':<8} {'å¯¦éš›':>6} {'èª¤å·®':>8}")
        print("-" * 80)

        for _, row in predictions.iterrows():
            ci = f"[{row['lower_bound']:.0f}-{row['upper_bound']:.0f}]"
            risk_emoji = {'HIGH': 'ğŸ”´', 'MEDIUM-HIGH': 'ğŸŸ ', 'MEDIUM': 'ğŸŸ¡', 'LOW': 'ğŸŸ¢'}
            emoji = risk_emoji.get(row['risk_level'], '')

            actual_str = f"{row['actual_sorties']:.0f}" if pd.notna(row['actual_sorties']) else '-'
            error_str = f"{row['prediction_error']:+.1f}" if pd.notna(row['prediction_error']) else '-'

            print(f"{row['date']:<12} {row['day_of_week']:<10} {row['predicted_sorties']:>8.1f} {ci:>15} "
                  f"{row['high_event_probability']:>9.1f}% {emoji} {row['risk_level']:<8} {actual_str:>6} {error_str:>8}")

        print("-" * 80)
        print(f"å¹³å‡é æ¸¬: {predictions['predicted_sorties'].mean():.1f} æ¶æ¬¡")
        print(f"æœ€é«˜é¢¨éšªæ—¥: {predictions.loc[predictions['high_event_probability'].idxmax(), 'date']}")

        return predictions


# ============================================================
# ä¸»ç¨‹å¼
# ============================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='PLA 7-Day Sorties Prediction')
    parser.add_argument('--sorties', type=str, default=None, help='Path to sorties data')
    parser.add_argument('--political', type=str, default=None, help='Path to political events data')
    parser.add_argument('--output', type=str, default='prediction.csv', help='Output file path')
    
    args = parser.parse_args()
    
    predictor = PLAPredictor(high_threshold=HIGH_THRESHOLD)
    predictions = predictor.run(
        sorties_path=args.sorties,
        political_path=args.political,
        output_path=args.output
    )

