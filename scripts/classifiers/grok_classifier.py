#!/usr/bin/env python3
"""
===============================================================================
Grok API æ–°èåˆ†é¡å™¨ / Grok News Classifier
===============================================================================

ä½¿ç”¨ Grok API (via apertis.ai) é€²è¡Œæ–°èåˆ†é¡å’Œæƒ…ç·’åˆ†æ
æ”¯æ´ GDELT é¢¨æ ¼çš„æƒ…ç·’åˆ†æ•¸ (-1 åˆ° +1)
"""

import json
import httpx
import time
from typing import List, Dict, Optional
from .prompts import (
    CLASSIFICATION_SYSTEM_PROMPT,
    CLASSIFICATION_USER_TEMPLATE,
    DEDUP_SYSTEM_PROMPT,
    DEDUP_USER_TEMPLATE,
)


class GrokNewsClassifier:
    """ä½¿ç”¨ Grok API é€²è¡Œæ–°èåˆ†é¡å’Œæƒ…ç·’åˆ†æ"""

    # å¯é‡è©¦çš„ HTTP ç‹€æ…‹ç¢¼
    RETRYABLE_STATUS_CODES = {429, 500, 502, 503, 504}
    MAX_RETRIES = 5
    RETRY_DELAYS = [10, 30, 60, 120, 240]  # é€€é¿æ™‚é–“ï¼ˆç§’ï¼‰
    
    def __init__(self, api_key: str):
        self.api_key = api_key.strip()
        self.api_url = "https://api.apertis.ai/v1/chat/completions"
        self.model = "glm-4.5-air:free"
        # trust_env=False é˜²æ­¢ CI/CD ç’°å¢ƒä»£ç†è¨­å®šå¹²æ“¾
        self.client = httpx.Client(timeout=60, trust_env=False)
        self._debug_printed = False

        # åˆå§‹åŒ–æ™‚å°å‡ºè¨ºæ–·è³‡è¨Š
        masked_key = self.api_key[:8] + "..." + self.api_key[-4:] if len(self.api_key) > 12 else "***"
        print(f"[GrokClassifier] ========== è¨ºæ–·è³‡è¨Š ==========")
        print(f"[GrokClassifier] API URL  : {self.api_url}")
        print(f"[GrokClassifier] Model    : {self.model}")
        print(f"[GrokClassifier] API Key  : {masked_key} (length={len(self.api_key)})")
        print(f"[GrokClassifier] Retries  : max {self.MAX_RETRIES} (backoff: {', '.join(str(d)+'s' for d in self.RETRY_DELAYS)})")
        print(f"[GrokClassifier] ================================")
    
    def _call_api(self, messages: List[Dict]) -> Optional[str]:
        """
        èª¿ç”¨ APIï¼Œå«è‡ªå‹•é‡è©¦ (503/429/500 ç­‰éŒ¯èª¤æœƒé‡è©¦)
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            API å›æ‡‰å…§å®¹ï¼Œå¤±æ•—æ™‚è¿”å› None
        """
        last_error = None

        for attempt in range(1, self.MAX_RETRIES + 1):
            try:
                response = self.client.post(
                    self.api_url,
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": messages,
                        "temperature": 0.1
                    }
                )

                # æˆåŠŸ
                if response.status_code == 200:
                    return response.json()["choices"][0]["message"]["content"]

                # å¯é‡è©¦çš„éŒ¯èª¤
                if response.status_code in self.RETRYABLE_STATUS_CODES:
                    # 429 å„ªå…ˆè®€å– Retry-After header
                    retry_after = None
                    if response.status_code == 429:
                        retry_after = response.headers.get('Retry-After')
                    
                    if retry_after:
                        try:
                            wait_time = int(float(retry_after))
                        except (ValueError, TypeError):
                            wait_time = self.RETRY_DELAYS[min(attempt - 1, len(self.RETRY_DELAYS) - 1)]
                    else:
                        wait_time = self.RETRY_DELAYS[min(attempt - 1, len(self.RETRY_DELAYS) - 1)]
                    
                    print(f"[GrokClassifier] âš ï¸  HTTP {response.status_code} (attempt {attempt}/{self.MAX_RETRIES})")
                    print(f"[GrokClassifier]    Body: {response.text[:200]}")
                    if attempt < self.MAX_RETRIES:
                        if retry_after:
                            print(f"[GrokClassifier]    Retry-After: {retry_after}sï¼Œç­‰å¾… {wait_time}s å¾Œé‡è©¦...")
                        else:
                            print(f"[GrokClassifier]    ç­‰å¾… {wait_time}s å¾Œé‡è©¦...")
                        time.sleep(wait_time)
                        continue
                    else:
                        print(f"[GrokClassifier] âŒ å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œæ”¾æ£„æ­¤è«‹æ±‚")
                        return None

                # ä¸å¯é‡è©¦çš„éŒ¯èª¤ (401, 403, 400 ç­‰)
                print(f"[GrokClassifier] âŒ HTTP {response.status_code} (ä¸å¯é‡è©¦)")
                print(f"[GrokClassifier]    Body: {response.text[:300]}")
                if response.status_code in (401, 403):
                    print(f"[GrokClassifier]    ğŸ”‘ è«‹æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢ºã€æ˜¯å¦éæœŸ")
                return None

            except httpx.ConnectError as e:
                wait_time = self.RETRY_DELAYS[min(attempt - 1, len(self.RETRY_DELAYS) - 1)]
                print(f"[GrokClassifier] âš ï¸  é€£ç·šå¤±æ•— (attempt {attempt}/{self.MAX_RETRIES}): {e}")
                if attempt < self.MAX_RETRIES:
                    print(f"[GrokClassifier]    ç­‰å¾… {wait_time}s å¾Œé‡è©¦...")
                    time.sleep(wait_time)
                    continue
                print(f"[GrokClassifier] âŒ é€£ç·šå¤±æ•—å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
                return None

            except httpx.TimeoutException as e:
                wait_time = self.RETRY_DELAYS[min(attempt - 1, len(self.RETRY_DELAYS) - 1)]
                print(f"[GrokClassifier] âš ï¸  è«‹æ±‚è¶…æ™‚ (attempt {attempt}/{self.MAX_RETRIES}): {e}")
                if attempt < self.MAX_RETRIES:
                    print(f"[GrokClassifier]    ç­‰å¾… {wait_time}s å¾Œé‡è©¦...")
                    time.sleep(wait_time)
                    continue
                print(f"[GrokClassifier] âŒ è¶…æ™‚å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
                return None

            except Exception as e:
                print(f"[GrokClassifier] âŒ æœªé æœŸéŒ¯èª¤: {type(e).__name__}: {e}")
                return None

        return None
    
    def classify_single(self, article: Dict) -> Dict:
        """
        åˆ†é¡å–®ç¯‡æ–°èä¸¦é€²è¡Œæƒ…ç·’åˆ†æ
        
        Args:
            article: æ–°èå­—å…¸ {date, title, content, url, source}
            
        Returns:
            åˆ†é¡çµæœ {
                category, is_relevant, sentiment_score, sentiment_label,
                extracted_data, confidence
            }
        """
        # æ§‹å»ºç”¨æˆ¶æ¶ˆæ¯
        user_message = CLASSIFICATION_USER_TEMPLATE.format(
            title=article.get('title', ''),
            content=article.get('content', '')[:500],  # é™åˆ¶å…§å®¹é•·åº¦
            date=article.get('date', ''),
            source=article.get('source', '')
        )
        
        messages = [
            {"role": "system", "content": CLASSIFICATION_SYSTEM_PROMPT},
            {"role": "user", "content": user_message}
        ]
        
        response = self._call_api(messages)
        
        if not response:
            return self._default_result(article)
        
        return self._parse_response(response, article)
    
    def _parse_response(self, response: str, article: Dict) -> Dict:
        """è§£æ API å›æ‡‰"""
        try:
            # å˜—è©¦æå– JSON
            json_match = response
            
            # å¦‚æœå›æ‡‰åŒ…å« ```json ... ``` æ ¼å¼
            if '```json' in response:
                import re
                match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
                if match:
                    json_match = match.group(1)
            elif '```' in response:
                import re
                match = re.search(r'```\s*(.*?)\s*```', response, re.DOTALL)
                if match:
                    json_match = match.group(1)
            
            result = json.loads(json_match)
            
            # ç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨
            return {
                'category': result.get('category', 'Not_Relevant'),
                'is_relevant': result.get('is_relevant', False),
                'country1': result.get('country1', ''),
                'country2': result.get('country2', ''),
                'sentiment_score': float(result.get('sentiment_score', 0)),
                'sentiment_label': result.get('sentiment_label', 'neutral'),
                'extracted_data': result.get('extracted_data', {}),
                'confidence': float(result.get('confidence', 0.5)),
                'original_article': article
            }
            
        except (json.JSONDecodeError, KeyError, TypeError) as e:
            print(f"[GrokClassifier] Parse error: {e}")
            return self._default_result(article)
    
    def _default_result(self, article: Dict) -> Dict:
        """è¿”å›é»˜èªçµæœï¼ˆè§£æå¤±æ•—æ™‚ä½¿ç”¨ï¼‰"""
        return {
            'category': 'Not_Relevant',
            'is_relevant': False,
            'country1': '',
            'country2': '',
            'sentiment_score': 0.0,
            'sentiment_label': 'neutral',
            'extracted_data': {},
            'confidence': 0.0,
            'original_article': article
        }
    
    # ------------------------------------------------------------------
    # å»é‡ / Deduplication
    # ------------------------------------------------------------------
    def _build_dedup_list(self, articles: List[Dict]) -> str:
        """å°‡æ–‡ç« åˆ—è¡¨æ ¼å¼åŒ–ç‚ºå»é‡ Prompt ç”¨çš„æ–‡å­—"""
        lines = []
        for i, a in enumerate(articles):
            title = a.get("title", "")[:60]
            content = a.get("content", "")[:80]
            source = a.get("source", "")
            date = a.get("date", "")
            lines.append(f"[{i}] ({source} {date}) {title} â€” {content}")
        return "\n".join(lines)

    def deduplicate_batch(
        self, articles: List[Dict], batch_size: int = 30
    ) -> List[Dict]:
        """
        ä½¿ç”¨ LLM è­˜åˆ¥ä¸¦ç§»é™¤é‡è¤‡/é«˜åº¦ç›¸ä¼¼çš„æ–‡ç« ã€‚

        å°‡æ–‡ç« åˆ†æ‰¹é€çµ¦ LLMï¼ˆæ¯æ‰¹ batch_size ç¯‡ï¼‰ï¼Œ
        LLM å›å‚³é‡è¤‡çµ„ï¼Œæ¯çµ„ä¿ç•™ç¬¬ä¸€ç¯‡ï¼ˆæœ€å®Œæ•´çš„ï¼‰ï¼Œå…¶é¤˜å‰”é™¤ã€‚

        Args:
            articles: åŸå§‹æ–‡ç« åˆ—è¡¨
            batch_size: æ¯æ‰¹é€çµ¦ LLM çš„æ–‡ç« æ•¸

        Returns:
            å»é‡å¾Œçš„æ–‡ç« åˆ—è¡¨
        """
        if len(articles) <= 1:
            return articles

        print(f"[GrokClassifier] é–‹å§‹å»é‡ï¼Œå…± {len(articles)} ç¯‡æ–‡ç« ...")

        # å…ˆåš URL å®Œå…¨æ¯”å°å»é‡
        seen_urls = set()
        url_deduped = []
        for a in articles:
            url = a.get("url", "")
            if url and url in seen_urls:
                continue
            if url:
                seen_urls.add(url)
            url_deduped.append(a)

        removed_by_url = len(articles) - len(url_deduped)
        if removed_by_url:
            print(f"[GrokClassifier]   URL å®Œå…¨æ¯”å°å»é‡: ç§»é™¤ {removed_by_url} ç¯‡")

        # LLM èªç¾©å»é‡ï¼ˆåˆ†æ‰¹è™•ç†ï¼‰
        all_keep_indices = set(range(len(url_deduped)))

        for start in range(0, len(url_deduped), batch_size):
            batch = url_deduped[start : start + batch_size]
            if len(batch) <= 1:
                continue

            article_list_text = self._build_dedup_list(batch)
            user_msg = DEDUP_USER_TEMPLATE.format(
                count=len(batch), article_list=article_list_text
            )

            messages = [
                {"role": "system", "content": DEDUP_SYSTEM_PROMPT},
                {"role": "user", "content": user_msg},
            ]

            response = self._call_api(messages)
            if not response:
                print(f"[GrokClassifier]   æ‰¹æ¬¡ {start}-{start+len(batch)-1}: LLM ç„¡å›æ‡‰ï¼Œè·³é")
                continue

            # è§£æ LLM å›æ‡‰
            try:
                text = response
                if "```json" in text:
                    import re
                    m = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
                    if m:
                        text = m.group(1)
                elif "```" in text:
                    import re
                    m = re.search(r"```\s*(.*?)\s*```", text, re.DOTALL)
                    if m:
                        text = m.group(1)

                result = json.loads(text)
                groups = result.get("groups", [])

                batch_removed = 0
                for group in groups:
                    if not isinstance(group, list) or len(group) < 2:
                        continue
                    # group[0] ä¿ç•™ï¼Œå…¶é¤˜å‰”é™¤
                    for idx in group[1:]:
                        global_idx = start + idx
                        if 0 <= idx < len(batch) and global_idx in all_keep_indices:
                            all_keep_indices.discard(global_idx)
                            batch_removed += 1

                if batch_removed:
                    print(
                        f"[GrokClassifier]   æ‰¹æ¬¡ {start}-{start+len(batch)-1}: "
                        f"ç™¼ç¾ {len(groups)} çµ„é‡è¤‡ï¼Œç§»é™¤ {batch_removed} ç¯‡"
                    )

            except (json.JSONDecodeError, KeyError, TypeError) as e:
                print(f"[GrokClassifier]   æ‰¹æ¬¡å»é‡è§£æå¤±æ•—: {e}")

        deduped = [url_deduped[i] for i in sorted(all_keep_indices)]
        total_removed = len(articles) - len(deduped)
        print(
            f"[GrokClassifier] å»é‡å®Œæˆ: {len(articles)} â†’ {len(deduped)} "
            f"(ç§»é™¤ {total_removed} ç¯‡é‡è¤‡)"
        )
        return deduped

    def classify_batch(self, articles: List[Dict], delay: float = 1.0) -> List[Dict]:
        """
        æ‰¹é‡åˆ†é¡æ–°è
        
        Args:
            articles: æ–°èåˆ—è¡¨
            delay: è«‹æ±‚é–“éš”ï¼ˆç§’ï¼‰
            
        Returns:
            åˆ†é¡çµæœåˆ—è¡¨
        """
        results = []
        total = len(articles)
        
        for i, article in enumerate(articles, 1):
            print(f"[GrokClassifier] Processing {i}/{total}: {article.get('title', '')[:40]}...")
            
            result = self.classify_single(article)
            results.append(result)
            
            # é¿å… API é™æµ
            if i < total:
                time.sleep(delay)
        
        return results
    
    def filter_relevant(self, classified: List[Dict]) -> List[Dict]:
        """éæ¿¾å‡ºç›¸é—œæ–°è"""
        return [r for r in classified if r.get('is_relevant', False)]
    
    def close(self):
        """é—œé–‰é€£æ¥"""
        self.client.close()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


def test_classifier():
    """æ¸¬è©¦åˆ†é¡å™¨ï¼ˆéœ€è¦ API Keyï¼‰"""
    import os
    api_key = os.environ.get('GROK_API_KEY', '')
    
    if not api_key:
        print("GROK_API_KEY not set, skipping test")
        return
    
    sample_article = {
        'date': '2026-01-17',
        'title': 'å…±è»é€šå ±ç¾åœ‹2è‰˜è»è‰¦ç©¿è¶Šå°æµ·ã€€å·ç¿’æœƒå¾Œé¦–æ¬¡',
        'content': 'å…±è»æ±éƒ¨æˆ°å€ä»Šå¤©é€šå ±ï¼Œç¾åœ‹æµ·è»æ™®é›·å¸ƒçˆ¾è™Ÿé©…é€è‰¦åŠç‹„çˆ¾è™Ÿè£œçµ¦è‰¦17æ—¥éèˆªå°ç£æµ·å³½ï¼Œæ±éƒ¨æˆ°å€çµ„ç¹”æµ·ç©ºå…µåŠ›å…¨ç¨‹è·Ÿè¹¤ç›£è¦–ã€‚',
        'url': 'https://www.cna.com.tw/news/acn/202601170192.aspx',
        'source': 'cna'
    }
    
    classifier = GrokNewsClassifier(api_key)
    result = classifier.classify_single(sample_article)
    
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    classifier.close()


if __name__ == '__main__':
    test_classifier()
