#!/usr/bin/env python3
"""
===============================================================================
è³‡æ–™åˆä½µå™¨ / Data Merger
===============================================================================

å¾ GitHub ä¸‹è¼‰ JapanandBattleship.csv ä¸¦åˆä½µ pla_aircraft_sorties ç­‰æ¬„ä½
"""

import httpx
import pandas as pd
import numpy as np
from io import StringIO
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List


class DataMerger:
    """å¾å¤–éƒ¨è³‡æ–™æºåˆä½µæ•¸æ“š"""
    
    # GitHub Raw URLï¼ˆä¸»è¦ï¼‰
    JAPAN_BATTLESHIP_URL = (
        "https://raw.githubusercontent.com/s0914712/pla-data-dashboard/"
        "main/data/JapanandBattleship.csv"
    )
    
    # GitHub API URLï¼ˆå‚™ç”¨ï¼‰
    GITHUB_API_URL = (
        "https://api.github.com/repos/s0914712/pla-data-dashboard/"
        "contents/data/JapanandBattleship.csv"
    )
    
    # è¦å¾ JapanandBattleship.csv è¤‡è£½çš„æ¬„ä½
    MERGE_COLUMNS = [
        'pla_aircraft_sorties',
        'china_carrier_present',
        # å¦‚æœæœ‰å…¶ä»–æ¬„ä½ä¹Ÿå¯ä»¥åŠ å…¥
    ]
    
    def __init__(self, timeout: int = 30, local_path: Optional[str] = None):
        """
        åˆå§‹åŒ–
        
        Args:
            timeout: HTTP è«‹æ±‚è¶…æ™‚
            local_path: æœ¬åœ° JapanandBattleship.csv è·¯å¾‘ï¼ˆå„ªå…ˆä½¿ç”¨ï¼‰
        """
        self.timeout = timeout
        self.local_path = local_path
        self.client = httpx.Client(
            timeout=timeout,
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "application/vnd.github.v3.raw+json"
            }
        )
        self._japan_data: Optional[pd.DataFrame] = None
    
    def fetch_japan_battleship_data(self) -> Optional[pd.DataFrame]:
        """
        ç²å– JapanandBattleship.csv è³‡æ–™
        
        å„ªå…ˆé †åºï¼š
        1. æœ¬åœ°æª”æ¡ˆ
        2. GitHub Raw URL
        3. GitHub API
        
        Returns:
            DataFrame æˆ– Noneï¼ˆå¤±æ•—æ™‚ï¼‰
        """
        # 1. å˜—è©¦æœ¬åœ°æª”æ¡ˆ
        if self.local_path:
            local_file = Path(self.local_path)
            if local_file.exists():
                try:
                    print(f"[DataMerger] Loading from local: {self.local_path}")
                    df = pd.read_csv(local_file, encoding='utf-8-sig')
                    return self._process_dataframe(df)
                except Exception as e:
                    print(f"[DataMerger] Local file error: {e}")
        
        # 2. å˜—è©¦ GitHub Raw URL
        try:
            print(f"[DataMerger] Fetching from GitHub Raw...")
            response = self.client.get(self.JAPAN_BATTLESHIP_URL)
            if response.status_code == 200:
                df = pd.read_csv(StringIO(response.text), encoding='utf-8')
                return self._process_dataframe(df)
            else:
                print(f"[DataMerger] GitHub Raw returned: {response.status_code}")
        except Exception as e:
            print(f"[DataMerger] GitHub Raw error: {e}")
        
        # 3. å˜—è©¦ GitHub API
        try:
            print(f"[DataMerger] Fetching from GitHub API...")
            response = self.client.get(
                self.GITHUB_API_URL,
                headers={"Accept": "application/vnd.github.v3.raw"}
            )
            if response.status_code == 200:
                df = pd.read_csv(StringIO(response.text), encoding='utf-8')
                return self._process_dataframe(df)
            else:
                print(f"[DataMerger] GitHub API returned: {response.status_code}")
        except Exception as e:
            print(f"[DataMerger] GitHub API error: {e}")
        
        print("[DataMerger] All fetch methods failed")
        return None
    
    def _process_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """è™•ç†ä¸¦æ¨™æº–åŒ– DataFrame"""
        # æ¨™æº–åŒ–æ—¥æœŸæ¬„ä½
        if 'date' in df.columns:
            df['date_normalized'] = pd.to_datetime(
                df['date'], errors='coerce'
            ).dt.strftime('%Y/%m/%d')
        
        print(f"[DataMerger] Loaded {len(df)} rows")
        self._japan_data = df
        return df
    
    def merge_pla_sorties(self, target_df: pd.DataFrame) -> pd.DataFrame:
        """
        å°‡ pla_aircraft_sorties ç­‰æ¬„ä½åˆä½µåˆ°ç›®æ¨™ DataFrame
        
        Args:
            target_df: ç›®æ¨™ DataFrameï¼ˆä¸»æ•¸æ“šé›†ï¼‰
            
        Returns:
            åˆä½µå¾Œçš„ DataFrame
        """
        # ç¢ºä¿å·²ä¸‹è¼‰è³‡æ–™
        if self._japan_data is None:
            self.fetch_japan_battleship_data()
        
        if self._japan_data is None:
            print("[DataMerger] No source data available, skipping merge")
            return target_df
        
        source_df = self._japan_data.copy()
        result_df = target_df.copy()
        
        # æ¨™æº–åŒ–ç›®æ¨™ DataFrame çš„æ—¥æœŸ
        result_df['date_normalized'] = pd.to_datetime(
            result_df['date'], errors='coerce'
        ).dt.strftime('%Y/%m/%d')
        
        # å»ºç«‹ä¾†æºè³‡æ–™çš„æ—¥æœŸç´¢å¼•
        source_dict = {}
        for _, row in source_df.iterrows():
            date_key = row.get('date_normalized', '')
            if date_key and pd.notna(date_key):
                source_dict[date_key] = row
        
        # åˆä½µè³‡æ–™
        updated_count = 0
        for idx, row in result_df.iterrows():
            date_key = row.get('date_normalized', '')
            
            if date_key in source_dict:
                source_row = source_dict[date_key]
                
                # è¤‡è£½æŒ‡å®šæ¬„ä½
                for col in self.MERGE_COLUMNS:
                    if col in source_row.index:
                        source_val = source_row[col]
                        
                        # åªåœ¨ç›®æ¨™ç‚ºç©ºæ™‚æ›´æ–°
                        if col in result_df.columns:
                            current_val = result_df.loc[idx, col]
                            if pd.isna(current_val) or current_val == '':
                                if pd.notna(source_val):
                                    result_df.loc[idx, col] = source_val
                                    updated_count += 1
                        else:
                            # æ¬„ä½ä¸å­˜åœ¨ï¼Œæ–°å¢
                            result_df.loc[idx, col] = source_val
                            updated_count += 1
        
        # ç§»é™¤è‡¨æ™‚æ¬„ä½
        if 'date_normalized' in result_df.columns:
            result_df = result_df.drop(columns=['date_normalized'])
        
        print(f"[DataMerger] Merged {updated_count} values for pla_aircraft_sorties")
        return result_df
    
    def get_stats(self) -> Dict:
        """ç²å–ä¾†æºè³‡æ–™çµ±è¨ˆ"""
        if self._japan_data is None:
            return {'status': 'not_loaded'}
        
        df = self._japan_data
        stats = {
            'status': 'loaded',
            'total_rows': len(df),
            'columns': list(df.columns),
        }
        
        # çµ±è¨ˆ pla_aircraft_sorties
        if 'pla_aircraft_sorties' in df.columns:
            stats['pla_aircraft_sorties'] = {
                'non_null': int(df['pla_aircraft_sorties'].notna().sum()),
                'min': float(df['pla_aircraft_sorties'].min()) if df['pla_aircraft_sorties'].notna().any() else None,
                'max': float(df['pla_aircraft_sorties'].max()) if df['pla_aircraft_sorties'].notna().any() else None,
            }
        
        return stats
    
    def close(self):
        """é—œé–‰é€£æ¥"""
        self.client.close()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


def test_merger():
    """æ¸¬è©¦åˆä½µå™¨"""
    with DataMerger() as merger:
        # ä¸‹è¼‰è³‡æ–™
        df = merger.fetch_japan_battleship_data()
        
        if df is not None:
            print("\nğŸ“Š Source Data Stats:")
            print(merger.get_stats())
            
            # é¡¯ç¤ºå‰å¹¾è¡Œ
            print("\nğŸ“‹ Sample data:")
            cols = ['date', 'pla_aircraft_sorties', 'china_carrier_present']
            available_cols = [c for c in cols if c in df.columns]
            print(df[available_cols].head(10).to_string())


if __name__ == '__main__':
    test_merger()
