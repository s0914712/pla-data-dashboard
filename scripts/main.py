#!/usr/bin/env python3
"""
===============================================================================
ä¸»æ›´æ–°è…³æœ¬ / Main Update Script
===============================================================================

æ•´åˆ CNA / Xinhua çˆ¬èŸ²ã€Grok åˆ†é¡å™¨èˆ‡ GitHub æ›´æ–°å™¨
"""

import argparse
import json
import sys
from pathlib import Path
from datetime import datetime
import os

# ---------------------------------------------------------------------------
# Path è¨­å®š
# ---------------------------------------------------------------------------

# æ·»åŠ çˆ¶ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from scrapers.cna_scraper import CNAScraper
# from scrapers.xinhua_scraper import XinhuaScraper  # è‹¥å°šæœªå¯¦ä½œå¯å…ˆè¨»è§£
from classifiers.grok_classifier import GrokNewsClassifier
from updaters.github_updater import GitHubUpdater


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="Daily News Update Script")
    parser.add_argument("--days", type=int, default=7, help="Days back to scrape")
    parser.add_argument("--no-push", action="store_true", help="Skip GitHub push")
    args = parser.parse_args()

    print("=" * 70)
    print(f"ğŸš€ Starting Daily News Update - {datetime.now():%Y-%m-%d %H:%M:%S}")
    print(f"ğŸ“… Scraping news from past {args.days} days")
    print("=" * 70)

    all_articles = []
    stats = {
        "timestamp": datetime.now().isoformat(),
        "days_back": args.days,
        "sources": {}
    }

    # -----------------------------------------------------------------------
    # 1. CNA
    # -----------------------------------------------------------------------

    print("\n[1/4] çˆ¬å–ä¸­å¤®ç¤¾æ–°è...")
    try:
        with CNAScraper(delay=1.0) as cna:
            cna_articles = cna.run(days_back=args.days)
            all_articles.extend(cna_articles)

            stats["sources"]["cna"] = {
                "scraped": len(cna_articles),
                "status": "success"
            }

            print(f"âœ“ CNA: {len(cna_articles)} ç¯‡æ–°è")
    except Exception as e:
        print(f"âœ— CNA Error: {e}")
        stats["sources"]["cna"] = {
            "status": "failed",
            "error": str(e)
        }

    # -----------------------------------------------------------------------
    # 2. Xinhuaï¼ˆå¯é¸ï¼‰
    # -----------------------------------------------------------------------

    print("\n[2/4] çˆ¬å–æ–°è¯ç¤¾æ–°è...")
    try:
        # è‹¥ XinhuaScraper å°šæœªå¯¦ä½œï¼Œè«‹ç¶­æŒè¨»è§£
        # with XinhuaScraper(delay=1.0) as xinhua:
        #     xinhua_articles = xinhua.run(days_back=args.days)
        #     all_articles.extend(xinhua_articles)
        #
        #     stats["sources"]["xinhua"] = {
        #         "scraped": len(xinhua_articles),
        #         "status": "success"
        #     }
        #
        #     print(f"âœ“ Xinhua: {len(xinhua_articles)} ç¯‡æ–°è")

        print("âš ï¸  Xinhua scraper not enabled.")
        stats["sources"]["xinhua"] = {
            "status": "skipped"
        }

    except Exception as e:
        print(f"âœ— Xinhua Error: {e}")
        stats["sources"]["xinhua"] = {
            "status": "failed",
            "error": str(e)
        }

    if not all_articles:
        print("\nâŒ No articles scraped. Exiting.")
        sys.exit(1)

    print(f"\nğŸ“Š Total articles scraped: {len(all_articles)}")

    # -----------------------------------------------------------------------
    # 3. Grok åˆ†é¡
    # -----------------------------------------------------------------------

    print("\n[3/4] ä½¿ç”¨ Grok é€²è¡Œæ–°èåˆ†é¡...")
    api_key = os.environ.get("GROK_API_KEY")

    if not api_key:
        print("âŒ GROK_API_KEY not found in environment")
        sys.exit(1)

    try:
        with GrokNewsClassifier(api_key) as classifier:
            classified = classifier.classify_batch(all_articles, delay=1.0)
            relevant = classifier.filter_relevant(classified)

            stats["classification"] = {
                "total": len(classified),
                "relevant": len(relevant),
                "status": "success"
            }

            print(f"âœ“ Classified: {len(classified)} ç¯‡")
            print(f"âœ“ Relevant: {len(relevant)} ç¯‡")

    except Exception as e:
        print(f"âœ— Classification Error: {e}")
        stats["classification"] = {
            "status": "failed",
            "error": str(e)
        }
        sys.exit(1)

    # -----------------------------------------------------------------------
    # 4. å„²å­˜çµæœ
    # -----------------------------------------------------------------------

    print("\n[4/4] ä¿å­˜æ•¸æ“š...")
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)

    classified_file = data_dir / "news_classified.json"
    relevant_file = data_dir / "news_relevant.json"

    with classified_file.open("w", encoding="utf-8") as f:
        json.dump(classified, f, ensure_ascii=False, indent=2)

    with relevant_file.open("w", encoding="utf-8") as f:
        json.dump(relevant, f, ensure_ascii=False, indent=2)

    print(f"âœ“ Saved: {classified_file}")
    print(f"âœ“ Saved: {relevant_file}")

    # -----------------------------------------------------------------------
    # 5. GitHub æ¨é€
    # -----------------------------------------------------------------------

    if args.no_push:
        print("\n[5/5] Skipping GitHub push (--no-push)")
        return

    print("\n[5/5] æ¨é€åˆ° GitHub...")
    try:
        updater = GitHubUpdater()
        updater.configure_git(
            name="PLA Data Bot",
            email="bot@example.com"
        )

        updater.create_summary_log(stats, "data/last_update.json")

        success = updater.commit_and_push_data(
            data_files=[
                "data/news_classified.json",
                "data/news_relevant.json",
                "data/last_update.json"
            ],
            message=f"ğŸ¤– Auto-update: {datetime.now():%Y-%m-%d %H:%M}"
        )

        print("âœ“ Pushed to GitHub" if success else "âš ï¸  No changes to push")

    except Exception as e:
        print(f"âœ— GitHub Error: {e}")
        stats["github_push"] = {
            "status": "failed",
            "error": str(e)
        }

    print("\n" + "=" * 70)
    print("âœ… Update completed successfully!")
    print("=" * 70)


if __name__ == "__main__":
    main()
