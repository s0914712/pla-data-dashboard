name: Xinhua Scraper (æ–°è¯ç¤¾å°ç£é »é“)

on:
  schedule:
    # æ¯å¤© UTC 02:00 åŸ·è¡Œ (å°åŒ—æ™‚é–“ 10:00)ï¼ŒéŒ¯é–‹å…¶ä»– workflow
    - cron: '0 2 * * *'

  # å…è¨±æ‰‹å‹•è§¸ç™¼
  workflow_dispatch:
    inputs:
      days_back:
        description: 'çˆ¬å–éå»å¹¾å¤©çš„æ–°è'
        required: false
        default: '7'
        type: string

jobs:
  scrape-xinhua:
    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:
      # 1. æª¢å‡ºä»£ç¢¼
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      # 2. è¨­ç½® Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      # 3. å®‰è£ä¾è³´
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          playwright install chromium --with-deps

      # 4. åŸ·è¡Œæ–°è¯ç¤¾çˆ¬èŸ²
      - name: Run Xinhua scraper
        env:
          GROK_API_KEY: ${{ secrets.GROK_API_KEY }}
        run: |
          python scripts/crawl_xinhua.py \
            --days ${{ github.event.inputs.days_back || '7' }} \
            --no-push

      # 5. æäº¤ä¸¦æ¨é€è®Šæ›´
      - name: Commit and push data changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action Bot"

          git add data/news_classified.json data/news_relevant.json || true

          if git diff --staged --quiet; then
            echo "âœ“ No changes to commit"
          else
            git diff --staged --stat
            git commit -m "ğŸ¤– Xinhua auto-update: $(date +'%Y-%m-%d %H:%M:%S')"
            for i in 1 2 3 4; do
              git push && break
              echo "Push failed (attempt $i/4), pulling latest changes..."
              git pull --rebase origin main
              sleep $((2 ** i))
            done
            echo "âœ“ Changes pushed successfully"
          fi

      # 6. ä¸Šå‚³æ•¸æ“šå¿«ç…§
      - name: Upload data snapshot
        uses: actions/upload-artifact@v4
        if: success()
        with:
          name: xinhua-data-${{ github.run_number }}
          path: |
            data/news_classified.json
            data/news_relevant.json
          retention-days: 7
