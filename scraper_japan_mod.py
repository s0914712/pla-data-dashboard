#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥æœ¬é˜²è¡›çœä¸­åœ‹æµ·è»è‰¦è‰‡å‹•å‘çˆ¬èŸ² - GitHub Actions ç‰ˆæœ¬
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import re
import requests
from datetime import datetime
import PyPDF2
import io
from openai import OpenAI
import json
import os
import pandas as pd

# ==================== è¨­å®šå€ ====================

# CSV æ–‡ä»¶è·¯å¾‘
CSV_FILE = 'data/JapanandBattleship.csv'

# Stima API è¨­å®šï¼ˆå¾ç’°å¢ƒè®Šé‡è®€å–ï¼‰
STIMA_API_KEY = os.getenv('STIMA_API_KEY')
STIMA_MODEL = 'grok-4.1-fast:free'

# æ—¥æœ¬é˜²è¡›çœç¶²ç«™
BASE_URL = 'https://www.mod.go.jp/js/press/index.html'

# è¦çˆ¬å–çš„é æ•¸
MAX_PDFS = 10

# 0/1 åˆ†ææ¬„ä½
BINARY_FIELDS = ['ç©ºä¸­', 'è¯åˆæ¼”è¨“', 'è‰¦é€šé', 'èˆªæ¯æ´»å‹•', 'èˆ‡é‚£åœ‹', 'å®®å¤', 'å¤§ç¦¹', 'å°é¦¬', 'é€²', 'å‡º']

# =================================================


def init_driver():
    """åˆå§‹åŒ– Selenium WebDriver"""
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver


def extract_text_from_pdf(pdf_url):
    """å¾ PDF URL æå–æ–‡æœ¬"""
    try:
        response = requests.get(pdf_url, timeout=30)
        response.raise_for_status()

        pdf_file = io.BytesIO(response.content)
        pdf_reader = PyPDF2.PdfReader(pdf_file)

        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"

        return text.strip()
    except Exception as e:
        print(f"    âŒ PDF è®€å–å¤±æ•—: {e}")
        return None


def analyze_with_stima(pdf_text, date):
    """ä½¿ç”¨ Stima API åˆ†æ PDF æ–‡æœ¬"""

    prompt = f"""ä½ æ˜¯ä¸€å€‹å°ˆé–€åˆ†æä¸­åœ‹æµ·è»è‰¦è‰‡å‹•å‘çš„å°ˆå®¶ã€‚è«‹ä»”ç´°é–±è®€ä»¥ä¸‹æ—¥æœ¬é˜²è¡›çœç™¼å¸ƒçš„ä¸­åœ‹æµ·è»è‰¦è‰‡å‹•å‘å ±å‘Šï¼Œä¸¦æå–é—œéµè³‡è¨Šã€‚

å ±å‘Šæ—¥æœŸï¼š{date}

å ±å‘Šå…§å®¹ï¼š
{pdf_text}

è«‹æ ¹æ“šå ±å‘Šå…§å®¹ï¼Œåˆ¤æ–·ä»¥ä¸‹å„å€‹æ¬„ä½ï¼š

**0/1 æ¬„ä½ï¼ˆæ˜¯/å¦ï¼‰ï¼š**
1. **ç©ºä¸­**ï¼šæ˜¯å¦æœ‰ç©ºä¸­æ´»å‹•ï¼ˆé£›æ©Ÿã€ç›´å‡æ©Ÿç­‰ï¼‰ - å¡« 0 æˆ– 1
2. **è¯åˆæ¼”è¨“**ï¼šæ˜¯å¦æåˆ°è¯åˆæ¼”ç¿’æˆ–è¨“ç·´ - å¡« 0 æˆ– 1
3. **è‰¦é€šé**ï¼šæ˜¯å¦æœ‰è‰¦è‰‡é€šéç‰¹å®šæµ·åŸŸ - å¡« 0 æˆ– 1
4. **èˆªæ¯æ´»å‹•**ï¼šæ˜¯å¦æœ‰èˆªç©ºæ¯è‰¦ç›¸é—œæ´»å‹• - å¡« 0 æˆ– 1
5. **èˆ‡é‚£åœ‹**ï¼šæ˜¯å¦ç¶“éèˆ‡é‚£åœ‹å³¶é™„è¿‘ - å¡« 0 æˆ– 1
6. **å®®å¤**ï¼šæ˜¯å¦ç¶“éå®®å¤æµ·å³½ - å¡« 0 æˆ– 1
7. **å¤§ç¦¹**ï¼šæ˜¯å¦ç¶“éå¤§éš…æµ·å³½ - å¡« 0 æˆ– 1
8. **å°é¦¬**ï¼šæ˜¯å¦ç¶“éå°é¦¬æµ·å³½ - å¡« 0 æˆ– 1
9. **é€²**ï¼šè‰¦è‰‡æ˜¯å¦å‘æ±æµ·æ–¹å‘èˆªè¡Œï¼ˆå¾å¤ªå¹³æ´‹é€²å…¥æ±æµ·ï¼‰ - å¡« 0 æˆ– 1
10. **å‡º**ï¼šè‰¦è‰‡æ˜¯å¦å‘å¤ªå¹³æ´‹æ–¹å‘èˆªè¡Œï¼ˆå¾æ±æµ·å‡ºå‘å¤ªå¹³æ´‹ï¼‰ - å¡« 0 æˆ– 1

**æ–‡å­—æ¬„ä½ï¼š**
11. **è‰¦å‹**ï¼šæå–å…·é«”çš„è‰¦è‰‡å‹è™Ÿï¼Œä½¿ç”¨ä¸­æ–‡åç¨±ï¼ˆä¾‹å¦‚ï¼šæ—…æ´‹IIç´šé©…é€è‰¦ã€æ±Ÿé–‹ç´šè­·è¡›è‰¦ã€ç¾ä»£ç´šé©…é€è‰¦ã€ç¦æ± ç´šç¶œåˆè£œçµ¦è‰¦ç­‰ï¼‰
    - å¦‚æœå ±å‘Šä¸­æåˆ°å¤šè‰˜è‰¦è‰‡ï¼Œè«‹åˆ—å‡ºæ‰€æœ‰å‹è™Ÿï¼Œç”¨é “è™Ÿã€Œã€ã€åˆ†éš”
    - å¦‚æœæ²’æœ‰æåˆ°å…·é«”å‹è™Ÿï¼Œå¡«ã€ŒæœªæåŠã€
    - å„ªå…ˆä½¿ç”¨ä¸­æ–‡é€šç¨±ï¼ˆæ—…æ´‹ã€æ±Ÿé–‹ã€ç¾ä»£ç´šç­‰ï¼‰

12. **remark**ï¼šç”¨ç¹é«”ä¸­æ–‡æ’°å¯« 70 å­—ä»¥å…§çš„ç°¡è¦æè¿°ï¼Œæ¦‚è¿°æ­¤æ¬¡æ´»å‹•çš„é‡é»
    - åŒ…å«ï¼šè‰¦è‰‡æ•¸é‡ã€ç¶“éæµ·åŸŸã€èˆªè¡Œæ–¹å‘ã€ä¸»è¦æ´»å‹•
    - ä½¿ç”¨ç°¡æ½”çš„æ›¸é¢èª
    - ä¸è¶…é 70 å€‹ä¸­æ–‡å­—

è«‹ä»¥ JSON æ ¼å¼å›è¦†ï¼Œåªå›è¦† JSONï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{{
  "ç©ºä¸­": 0,
  "è¯åˆæ¼”è¨“": 0,
  "è‰¦é€šé": 0,
  "èˆªæ¯æ´»å‹•": 0,
  "èˆ‡é‚£åœ‹": 0,
  "å®®å¤": 0,
  "å¤§ç¦¹": 0,
  "å°é¦¬": 0,
  "é€²": 0,
  "å‡º": 0,
  "è‰¦å‹": "æ—…æ´‹IIç´šé©…é€è‰¦ã€æ±Ÿé–‹ç´šè­·è¡›è‰¦",
  "remark": "ä¸­åœ‹æµ·è»2è‰˜è‰¦è‰‡ç”±æ±æµ·ç¶“å°é¦¬æµ·å³½å‘æ—¥æœ¬æµ·èˆªè¡Œï¼ŒåŒ…æ‹¬æ—…æ´‹IIç´šé©…é€è‰¦åŠæ±Ÿé–‹ç´šè­·è¡›è‰¦ã€‚"
}}
"""

    try:
        client = OpenAI(
            api_key=STIMA_API_KEY,
            base_url="https://api.stima.tech/v1/"
        )

        chat_completion = client.chat.completions.create(
            model=STIMA_MODEL,
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.1
        )

        response_text = chat_completion.choices[0].message.content

        # æå– JSON
        response_text = response_text.strip()
        if response_text.startswith('```json'):
            response_text = response_text[7:]
        if response_text.startswith('```'):
            response_text = response_text[3:]
        if response_text.endswith('```'):
            response_text = response_text[:-3]
        response_text = response_text.strip()

        # è§£æ JSON
        result = json.loads(response_text)

        return result

    except Exception as e:
        print(f"    âŒ Stima API åˆ†æå¤±æ•—: {e}")
        return None


def get_latest_date_from_csv():
    """å¾ CSV è®€å–æœ€æ–°æ—¥æœŸï¼ˆå«æ—¥æœ¬é˜²è¡›çœæ•¸æ“šçš„æ—¥æœŸï¼‰"""
    try:
        if not os.path.exists(CSV_FILE):
            print(f"âš ï¸ CSV æª”æ¡ˆä¸å­˜åœ¨: {CSV_FILE}")
            return None
            
        df = pd.read_csv(CSV_FILE, encoding='utf-8-sig')
        
        if df.empty or 'date' not in df.columns:
            return None
        
        # éæ¿¾å‡ºæœ‰è‰¦å‹æˆ– remark æ•¸æ“šçš„è¡Œï¼ˆè¡¨ç¤ºå·²è™•ç†éæ—¥æœ¬é˜²è¡›çœæ•¸æ“šï¼‰
        df_filtered = df[(df['è‰¦å‹'].notna() & (df['è‰¦å‹'] != '')) | 
                         (df['remark'].notna() & (df['remark'] != ''))]
        
        if df_filtered.empty:
            return None
        
        # è½‰æ›æ—¥æœŸä¸¦æ‰¾å‡ºæœ€æ–°çš„
        dates = pd.to_datetime(df_filtered['date'], format='%Y/%m/%d', errors='coerce')
        latest_date = dates.max()
        
        if pd.isna(latest_date):
            return None
            
        return latest_date
        
    except Exception as e:
        print(f"è®€å– CSV æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None


def check_date_data_validity(date, df):
    """æª¢æŸ¥æŒ‡å®šæ—¥æœŸçš„è³‡æ–™æ˜¯å¦æœ‰æ•ˆï¼ˆè‡³å°‘æœ‰ä¸€å€‹0/1æ¬„ä½ç‚º1ï¼‰"""
    try:
        # æ‰¾åˆ°å°æ‡‰æ—¥æœŸçš„è¡Œ
        mask = df['date'] == date
        
        if not mask.any():
            return False
        
        row = df[mask].iloc[0]
        
        # æª¢æŸ¥æ‰€æœ‰ 0/1 æ¬„ä½
        for field in BINARY_FIELDS:
            if field in row and pd.notna(row[field]):
                value = str(row[field]).strip()
                if value in ['1', '1.0']:
                    return True
        
        return False
        
    except Exception as e:
        print(f"      âš ï¸  æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False


def update_csv(date, data):
    """æ›´æ–° CSV æ–‡ä»¶ä¸­æŒ‡å®šæ—¥æœŸçš„è³‡æ–™"""
    try:
        if not os.path.exists(CSV_FILE):
            print(f"âŒ CSV æª”æ¡ˆä¸å­˜åœ¨: {CSV_FILE}")
            return False
            
        df = pd.read_csv(CSV_FILE, encoding='utf-8-sig')
        
        # æ‰¾åˆ°å°æ‡‰æ—¥æœŸçš„è¡Œ
        mask = df['date'] == date
        
        if not mask.any():
            print(f"      âš ï¸  æ‰¾ä¸åˆ°æ—¥æœŸ {date} çš„è¡Œ")
            return False
        
        # æ›´æ–°æ•¸æ“š
        for key, value in data.items():
            if key in df.columns:
                df.loc[mask, key] = value
        
        # å„²å­˜ï¼ˆä¿æŒåŸæœ‰çš„ç·¨ç¢¼å’Œæ ¼å¼ï¼‰
        df.to_csv(CSV_FILE, index=False, encoding='utf-8-sig')
        print(f"      âœ“ å·²æ›´æ–°æ—¥æœŸ {date} çš„è³‡æ–™")
        return True
        
    except Exception as e:
        print(f"      âŒ æ›´æ–°è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»ç¨‹å¼"""

    print("="*60)
    print("æ—¥æœ¬é˜²è¡›çœä¸­åœ‹æµ·è»è‰¦è‰‡å‹•å‘çˆ¬èŸ² V3 - GitHub Actions ç‰ˆ")
    print("="*60)
    
    # æª¢æŸ¥ API Key
    if not STIMA_API_KEY:
        print("âŒ éŒ¯èª¤ï¼šæœªè¨­ç½® STIMA_API_KEY ç’°å¢ƒè®Šé‡")
        return

    # è®€å– CSV
    print("\næ­£åœ¨è®€å– CSV...")
    try:
        df = pd.read_csv(CSV_FILE, encoding='utf-8-sig')
        print(f"âœ… æˆåŠŸè®€å–: {CSV_FILE}")
        print(f"ğŸ“Š ç¸½è¡Œæ•¸: {len(df)}")
    except Exception as e:
        print(f"âŒ è®€å–å¤±æ•—: {e}")
        return

    # å–å¾—æœ€æ–°æ—¥æœŸ
    latest_date = get_latest_date_from_csv()
    if latest_date:
        print(f"ğŸ“… æœ€æ–°æ—¥æœ¬é˜²è¡›çœè³‡æ–™æ—¥æœŸ: {latest_date.strftime('%Y/%m/%d')}")
    else:
        print(f"ğŸ“… ç„¡ç¾æœ‰æ—¥æœ¬é˜²è¡›çœè³‡æ–™")
        latest_date = datetime.min

    # é–‹å§‹çˆ¬å–
    print(f"\n{'='*60}")
    print("ğŸš€ é–‹å§‹çˆ¬å–æ—¥æœ¬é˜²è¡›çœè³‡æ–™...")
    print(f"{'='*60}\n")

    driver = init_driver()
    print("âœ“ ç€è¦½å™¨å•Ÿå‹•æˆåŠŸ\n")

    updated_pdfs = 0

    try:
        print(f"ğŸ“„ è¨ªå•: {BASE_URL}")
        driver.get(BASE_URL)
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        time.sleep(3)

        soup = BeautifulSoup(driver.page_source, "html.parser")

        # æ‰¾æ‰€æœ‰ PDF é€£çµ
        all_links = soup.find_all('a', href=re.compile(r'\.pdf$', re.I))

        china_navy_links = []
        for link in all_links:
            text = link.get_text(strip=True)
            if 'ä¸­å›½' in text or 'è‰¦è‰‡' in text or 'å‹•å‘' in text:
                china_navy_links.append(link)
            else:
                parent = link.find_parent(['p', 'li', 'div'])
                if parent:
                    parent_text = parent.get_text()
                    if 'ä¸­å›½' in parent_text and 'è‰¦è‰‡' in parent_text:
                        china_navy_links.append(link)

        print(f"  æ‰¾åˆ° {len(china_navy_links)} å€‹ä¸­åœ‹æµ·è»ç›¸é—œ PDF\n")

        for idx, link in enumerate(china_navy_links[:MAX_PDFS], 1):
            try:
                href = link.get('href')

                # æ§‹å»ºå®Œæ•´ URL
                if href.startswith('http'):
                    pdf_url = href
                elif href.startswith('/'):
                    pdf_url = f"https://www.mod.go.jp{href}"
                else:
                    pdf_url = f"https://www.mod.go.jp/js/press/{href}"

                print(f"  [{idx:2d}/{min(len(china_navy_links), MAX_PDFS)}] ğŸ“¥ {pdf_url}")

                # æå–æ—¥æœŸ
                link_text = link.get_text(strip=True)
                date_match = re.search(r'(\d{4})[å¹´/.-](\d{1,2})[æœˆ/.-](\d{1,2})', link_text + href)

                if date_match:
                    year = date_match.group(1)
                    month = date_match.group(2).zfill(2)
                    day = date_match.group(3).zfill(2)
                    date = f"{year}/{month}/{day}"
                else:
                    date = datetime.now().strftime('%Y/%m/%d')

                print(f"      ğŸ“… æ—¥æœŸ: {date}")

                # æª¢æŸ¥æ—¥æœŸå’Œè³‡æ–™å®Œæ•´æ€§
                try:
                    current_date = datetime.strptime(date, '%Y/%m/%d')
                    if current_date <= latest_date:
                        is_valid = check_date_data_validity(date, df)
                        if is_valid:
                            print(f"      â­ï¸  å·²å­˜åœ¨ä¸”è³‡æ–™æœ‰æ•ˆï¼Œè·³é\n")
                            continue
                        else:
                            print(f"      âš ï¸  å·²å­˜åœ¨ä½†è³‡æ–™å…¨ç‚º0ï¼Œé‡æ–°è™•ç†")
                except:
                    pass

                # æå– PDF æ–‡æœ¬
                print(f"      ğŸ“„ æå–æ–‡æœ¬...", end=" ")
                pdf_text = extract_text_from_pdf(pdf_url)

                if not pdf_text:
                    print("å¤±æ•—\n")
                    continue

                print(f"âœ“ ({len(pdf_text)} å­—)")

                # ä½¿ç”¨ Stima API åˆ†æ
                print(f"      ğŸ¤– AI åˆ†æä¸­...", end=" ")
                analysis = analyze_with_stima(pdf_text, date)

                if not analysis:
                    print("å¤±æ•—\n")
                    continue

                print("âœ“")

                # æ›´æ–° CSV
                if update_csv(date, analysis):
                    updated_pdfs += 1

                # é¡¯ç¤ºçµæœ
                print(f"      âœ… {date}:")
                binary_str = " | ".join([f"{k}:{v}" for k, v in analysis.items() if k in BINARY_FIELDS and v == 1])
                if binary_str:
                    print(f"         {binary_str}")
                if 'è‰¦å‹' in analysis and analysis['è‰¦å‹'] and analysis['è‰¦å‹'] != 'æœªæåŠ':
                    print(f"         è‰¦å‹: {analysis['è‰¦å‹']}")
                if 'remark' in analysis and analysis['remark']:
                    remark_display = analysis['remark'][:50] + '...' if len(analysis['remark']) > 50 else analysis['remark']
                    print(f"         å‚™è¨»: {remark_display}")
                print()

                time.sleep(2)  # é¿å…è«‹æ±‚éå¿«

            except Exception as e:
                print(f"      âŒ è™•ç†å¤±æ•—: {e}\n")
                import traceback
                traceback.print_exc()
                continue

    except Exception as e:
        print(f"âŒ çˆ¬å–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

    finally:
        driver.quit()
        print("âœ“ ç€è¦½å™¨å·²é—œé–‰")

    # é¡¯ç¤ºç¸½çµ
    print(f"\n{'='*60}")
    if updated_pdfs > 0:
        print(f"âœ… å®Œæˆï¼")
        print(f"ğŸ“Š ç¸½å…±æ›´æ–° {updated_pdfs} ç­†è³‡æ–™")
    else:
        print("â„¹ï¸  æ²’æœ‰éœ€è¦æ›´æ–°çš„è³‡æ–™")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
